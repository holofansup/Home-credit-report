{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_test:  (356251, 76)\n",
      "App_train and App_test - done in 1s\n",
      "Shape of Bureau_bb:  (305811, 145)\n",
      "Bureau and Bureau_balance - done in 5s\n",
      "Shape of previous:  (338857, 193)\n",
      "Previous - done in 6s\n",
      "Shape of Pos_cash:  (337252, 27)\n",
      "POS_CASH - done in 1s\n",
      "Shape of instalments:  (339587, 133)\n",
      "Instalment - done in 4s\n",
      "Shape of Credit_card:  (103558, 72)\n",
      "Credit_Card - done in 3s\n"
     ]
    }
   ],
   "source": [
    "with timer('App_train and App_test'):\n",
    "    df = pd.read_parquet('TO_TRAIN/train_test.gzip')\n",
    "    print('Shape of train_test: ', df.shape)\n",
    "with timer(\"Bureau and Bureau_balance\"):\n",
    "    bureau = pd.read_parquet('TO_TRAIN/bureau.gzip')\n",
    "    df = df.merge(bureau, on= 'SK_ID_CURR', how= 'left')\n",
    "    print(\"Shape of Bureau_bb: \", bureau.shape)\n",
    "    del bureau; gc.collect()\n",
    "with timer(\"Previous\"):\n",
    "    prev = pd.read_parquet('TO_TRAIN/prev.gzip')\n",
    "    df = df.merge(prev, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(\"Shape of previous: \", prev.shape)\n",
    "    del prev; gc.collect()\n",
    "with timer(\"POS_CASH\"):\n",
    "    pos = pd.read_parquet('TO_TRAIN/pos.gzip')\n",
    "    df = df.merge(pos, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(\"Shape of Pos_cash: \", pos.shape)\n",
    "    del pos; gc.collect()\n",
    "with timer(\"Instalment\"):\n",
    "    ins = pd.read_parquet('TO_TRAIN/ins.gzip')\n",
    "    df = df.merge(ins, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(\"Shape of instalments: \", ins.shape)\n",
    "    del ins; gc.collect()\n",
    "with timer(\"Credit_Card\"):\n",
    "    credit = pd.read_parquet('TO_TRAIN/credit.gzip')\n",
    "    df = df.merge(credit, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(\"Shape of Credit_card: \", credit.shape)\n",
    "    del credit; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDIT TO INCOME RATIO\n",
    "df['BUREAU_INCOME_CREDIT_RATIO'] = df['BUREAU_AMT_CREDIT_SUM_MEAN'] / df['AMT_INCOME_TOTAL']\n",
    "df['BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO'] = df['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_INCOME_TOTAL']\n",
    "# PREVIOUS TO CURRENT CREDIT RATIO\n",
    "df['CURRENT_TO_APPROVED_CREDIT_MIN_RATIO'] = df['APPROVED_AMT_CREDIT_MIN'] / df['AMT_CREDIT']\n",
    "df['CURRENT_TO_APPROVED_CREDIT_MAX_RATIO'] = df['APPROVED_AMT_CREDIT_MAX'] / df['AMT_CREDIT']\n",
    "df['CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO'] = df['APPROVED_AMT_CREDIT_MEAN'] / df['AMT_CREDIT']\n",
    "# PREVIOUS TO CURRENT ANNUITY RATIO\n",
    "df['CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO'] = df['APPROVED_AMT_ANNUITY_MAX'] / df['AMT_ANNUITY']\n",
    "df['CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO'] = df['APPROVED_AMT_ANNUITY_MEAN'] / df['AMT_ANNUITY']\n",
    "df['PAYMENT_MIN_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MIN'] / df['AMT_ANNUITY']\n",
    "df['PAYMENT_MAX_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MAX'] / df['AMT_ANNUITY']\n",
    "df['PAYMENT_MEAN_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MEAN'] / df['AMT_ANNUITY']\n",
    "# PREVIOUS TO CURRENT CREDIT TO ANNUITY RATIO\n",
    "# df['CTA_CREDIT_TO_ANNUITY_MAX_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MAX'] / df['CREDIT_TO_ANNUITY_RATIO']\n",
    "# df['CTA_CREDIT_TO_ANNUITY_MEAN_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MEAN'] / df['CREDIT_TO_ANNUITY_RATIO']\n",
    "# DAYS DIFFERENCES AND RATIOS\n",
    "df['DAYS_DECISION_MEAN_TO_BIRTH'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_BIRTH']\n",
    "df['DAYS_CREDIT_MEAN_TO_BIRTH'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_BIRTH']\n",
    "df['DAYS_DECISION_MEAN_TO_EMPLOYED'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_EMPLOYED']\n",
    "df['DAYS_CREDIT_MEAN_TO_EMPLOYED'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_EMPLOYED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:  (356251, 641)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataframe: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df['TARGET'].notnull()]\n",
    "test = df[df.TARGET.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quyk5\\AppData\\Local\\Temp\\ipykernel_13020\\2673995956.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.drop(columns= ['TARGET'], inplace= True)\n"
     ]
    }
   ],
   "source": [
    "test.drop(columns= ['TARGET'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (307507, 655) and test: (48744, 654)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train: {} and test: {}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO</th>\n",
       "      <th>CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO</th>\n",
       "      <th>CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO</th>\n",
       "      <th>PAYMENT_MIN_TO_ANNUITY_RATIO</th>\n",
       "      <th>PAYMENT_MAX_TO_ANNUITY_RATIO</th>\n",
       "      <th>PAYMENT_MEAN_TO_ANNUITY_RATIO</th>\n",
       "      <th>DAYS_DECISION_MEAN_TO_BIRTH</th>\n",
       "      <th>DAYS_CREDIT_MEAN_TO_BIRTH</th>\n",
       "      <th>DAYS_DECISION_MEAN_TO_EMPLOYED</th>\n",
       "      <th>DAYS_CREDIT_MEAN_TO_EMPLOYED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440374</td>\n",
       "      <td>0.374558</td>\n",
       "      <td>0.374558</td>\n",
       "      <td>0.374558</td>\n",
       "      <td>2.149501</td>\n",
       "      <td>0.467976</td>\n",
       "      <td>0.064052</td>\n",
       "      <td>0.092379</td>\n",
       "      <td>0.951334</td>\n",
       "      <td>1.372057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374326</td>\n",
       "      <td>2.755214</td>\n",
       "      <td>1.584212</td>\n",
       "      <td>0.186646</td>\n",
       "      <td>15.710334</td>\n",
       "      <td>1.813930</td>\n",
       "      <td>0.077841</td>\n",
       "      <td>0.083552</td>\n",
       "      <td>1.098485</td>\n",
       "      <td>1.179082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148933</td>\n",
       "      <td>0.793667</td>\n",
       "      <td>0.793667</td>\n",
       "      <td>0.793667</td>\n",
       "      <td>1.566513</td>\n",
       "      <td>1.051282</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.045521</td>\n",
       "      <td>3.622222</td>\n",
       "      <td>3.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099290</td>\n",
       "      <td>1.345881</td>\n",
       "      <td>0.735762</td>\n",
       "      <td>0.083638</td>\n",
       "      <td>23.303080</td>\n",
       "      <td>2.120394</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324832</td>\n",
       "      <td>1.037195</td>\n",
       "      <td>0.561561</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.037195</td>\n",
       "      <td>0.558600</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.057646</td>\n",
       "      <td>0.402513</td>\n",
       "      <td>0.378209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "0      100002     1.0                   0            0             0   \n",
       "1      100003     0.0                   0            1             0   \n",
       "2      100004     0.0                   1            0             1   \n",
       "3      100006     0.0                   0            1             0   \n",
       "4      100007     0.0                   0            0             0   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          202500.0    406597.5      24700.5         351000.0   \n",
       "1             0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2             0           67500.0    135000.0       6750.0         135000.0   \n",
       "3             0          135000.0    312682.5      29686.5         297000.0   \n",
       "4             0          121500.0    513000.0      21865.5         513000.0   \n",
       "\n",
       "   ...  CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO  \\\n",
       "0  ...                               0.440374   \n",
       "1  ...                               0.374326   \n",
       "2  ...                               0.148933   \n",
       "3  ...                               1.099290   \n",
       "4  ...                               0.324832   \n",
       "\n",
       "   CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO  \\\n",
       "0                               0.374558   \n",
       "1                               2.755214   \n",
       "2                               0.793667   \n",
       "3                               1.345881   \n",
       "4                               1.037195   \n",
       "\n",
       "   CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO  PAYMENT_MIN_TO_ANNUITY_RATIO  \\\n",
       "0                                0.374558                      0.374558   \n",
       "1                                1.584212                      0.186646   \n",
       "2                                0.793667                      0.793667   \n",
       "3                                0.735762                      0.083638   \n",
       "4                                0.561561                      0.000008   \n",
       "\n",
       "   PAYMENT_MAX_TO_ANNUITY_RATIO  PAYMENT_MEAN_TO_ANNUITY_RATIO  \\\n",
       "0                      2.149501                       0.467976   \n",
       "1                     15.710334                       1.813930   \n",
       "2                      1.566513                       1.051282   \n",
       "3                     23.303080                       2.120394   \n",
       "4                      1.037195                       0.558600   \n",
       "\n",
       "   DAYS_DECISION_MEAN_TO_BIRTH  DAYS_CREDIT_MEAN_TO_BIRTH  \\\n",
       "0                     0.064052                   0.092379   \n",
       "1                     0.077841                   0.083552   \n",
       "2                     0.042791                   0.045521   \n",
       "3                     0.018185                        NaN   \n",
       "4                     0.061350                   0.057646   \n",
       "\n",
       "   DAYS_DECISION_MEAN_TO_EMPLOYED  DAYS_CREDIT_MEAN_TO_EMPLOYED  \n",
       "0                        0.951334                      1.372057  \n",
       "1                        1.098485                      1.179082  \n",
       "2                        3.622222                      3.853333  \n",
       "3                        0.113722                           NaN  \n",
       "4                        0.402513                      0.378209  \n",
       "\n",
       "[5 rows x 650 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO</th>\n",
       "      <th>CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO</th>\n",
       "      <th>CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO</th>\n",
       "      <th>PAYMENT_MIN_TO_ANNUITY_RATIO</th>\n",
       "      <th>PAYMENT_MAX_TO_ANNUITY_RATIO</th>\n",
       "      <th>PAYMENT_MEAN_TO_ANNUITY_RATIO</th>\n",
       "      <th>DAYS_DECISION_MEAN_TO_BIRTH</th>\n",
       "      <th>DAYS_CREDIT_MEAN_TO_BIRTH</th>\n",
       "      <th>DAYS_DECISION_MEAN_TO_EMPLOYED</th>\n",
       "      <th>DAYS_CREDIT_MEAN_TO_EMPLOYED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041820</td>\n",
       "      <td>0.192165</td>\n",
       "      <td>0.192165</td>\n",
       "      <td>0.192165</td>\n",
       "      <td>0.846181</td>\n",
       "      <td>0.286235</td>\n",
       "      <td>0.090432</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.747102</td>\n",
       "      <td>0.315586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>100005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180248</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>1.016479</td>\n",
       "      <td>0.359252</td>\n",
       "      <td>0.041907</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.169389</td>\n",
       "      <td>0.042664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>100013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293768</td>\n",
       "      <td>0.331828</td>\n",
       "      <td>0.164498</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>5.121283</td>\n",
       "      <td>0.139591</td>\n",
       "      <td>0.052034</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>0.233887</td>\n",
       "      <td>0.389749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>100028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.229505</td>\n",
       "      <td>0.165072</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.795384</td>\n",
       "      <td>0.088879</td>\n",
       "      <td>0.097596</td>\n",
       "      <td>0.100297</td>\n",
       "      <td>0.730975</td>\n",
       "      <td>0.751206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307511</th>\n",
       "      <td>100038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148050</td>\n",
       "      <td>0.346169</td>\n",
       "      <td>0.346169</td>\n",
       "      <td>0.346071</td>\n",
       "      <td>0.346169</td>\n",
       "      <td>0.346161</td>\n",
       "      <td>0.062960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374715</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "307507      100001                   0            1             0   \n",
       "307508      100005                   0            0             0   \n",
       "307509      100013                   0            0             1   \n",
       "307510      100028                   0            1             0   \n",
       "307511      100038                   0            0             1   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "307507             0          135000.0    568800.0      20560.5   \n",
       "307508             0           99000.0    222768.0      17370.0   \n",
       "307509             0          202500.0    663264.0      69777.0   \n",
       "307510             2          315000.0   1575000.0      49018.5   \n",
       "307511             1          180000.0    625500.0      32067.0   \n",
       "\n",
       "        AMT_GOODS_PRICE  NAME_TYPE_SUITE  ...  \\\n",
       "307507         450000.0                0  ...   \n",
       "307508         180000.0                0  ...   \n",
       "307509         630000.0               -1  ...   \n",
       "307510        1575000.0                0  ...   \n",
       "307511         625500.0                0  ...   \n",
       "\n",
       "        CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO  \\\n",
       "307507                               0.041820   \n",
       "307508                               0.180248   \n",
       "307509                               0.293768   \n",
       "307510                               0.087891   \n",
       "307511                               0.148050   \n",
       "\n",
       "        CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO  \\\n",
       "307507                               0.192165   \n",
       "307508                               0.277098   \n",
       "307509                               0.331828   \n",
       "307510                               0.229505   \n",
       "307511                               0.346169   \n",
       "\n",
       "        CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO  PAYMENT_MIN_TO_ANNUITY_RATIO  \\\n",
       "307507                                0.192165                      0.192165   \n",
       "307508                                0.277098                      0.277098   \n",
       "307509                                0.164498                      0.000088   \n",
       "307510                                0.165072                      0.000024   \n",
       "307511                                0.346169                      0.346071   \n",
       "\n",
       "        PAYMENT_MAX_TO_ANNUITY_RATIO  PAYMENT_MEAN_TO_ANNUITY_RATIO  \\\n",
       "307507                      0.846181                       0.286235   \n",
       "307508                      1.016479                       0.359252   \n",
       "307509                      5.121283                       0.139591   \n",
       "307510                      0.795384                       0.088879   \n",
       "307511                      0.346169                       0.346161   \n",
       "\n",
       "        DAYS_DECISION_MEAN_TO_BIRTH  DAYS_CREDIT_MEAN_TO_BIRTH  \\\n",
       "307507                     0.090432                   0.038200   \n",
       "307508                     0.041907                   0.010555   \n",
       "307509                     0.052034                   0.086710   \n",
       "307510                     0.097596                   0.100297   \n",
       "307511                     0.062960                        NaN   \n",
       "\n",
       "        DAYS_DECISION_MEAN_TO_EMPLOYED  DAYS_CREDIT_MEAN_TO_EMPLOYED  \n",
       "307507                        0.747102                      0.315586  \n",
       "307508                        0.169389                      0.042664  \n",
       "307509                        0.233887                      0.389749  \n",
       "307510                        0.730975                      0.751206  \n",
       "307511                        0.374715                           NaN  \n",
       "\n",
       "[5 rows x 649 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('train.gzip', compression= 'gzip', index= False)\n",
    "test.to_parquet('test.gzip', compression= 'gzip', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_table(df, print_info = True):\n",
    "    # total missing value\n",
    "    mis_val = df.isnull().sum()\n",
    "\n",
    "    # percent missing value\n",
    "    percent_mis_val = 100*mis_val/len(df)\n",
    "\n",
    "    # make a table contain result\n",
    "    table = pd.concat([mis_val, percent_mis_val], axis=1)\n",
    "\n",
    "    # rename columns\n",
    "    table_re_col = table.rename(columns = {0: 'Missing Values', 1: '% Missing Value'})\n",
    "\n",
    "    # sort table by percent missing value descending\n",
    "    table_re_col = table_re_col[table_re_col.iloc[:,1] != 0].sort_values('% Missing Value', ascending= False).round(1)\n",
    "\n",
    "    if print_info:\n",
    "        # print something important\n",
    "        print(\"Dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
    "                \"There are \" + str(len(table_re_col)) + \" columns that have missing value.\"\n",
    "                )\n",
    "\n",
    "    return table_re_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df1, df2, thresh = 90, print_info = True):\n",
    "    \n",
    "    missing_table_df1 = missing_value_table(df1)\n",
    "    missing_table_df2 = missing_value_table(df2)\n",
    "\n",
    "    to_drop_df1 = list(missing_table_df1.loc[missing_table_df1['% Missing Value'] >= thresh].index)\n",
    "    to_drop_df2 = list(missing_table_df2.loc[missing_table_df2['% Missing Value'] >= thresh].index)\n",
    "    \n",
    "    missing_columns = list(set(to_drop_df1 + to_drop_df2))\n",
    "\n",
    "    df1 = df1.drop(columns = missing_columns)\n",
    "    df2 = df2.drop(columns = missing_columns)\n",
    "\n",
    "    if print_info:\n",
    "        print(\"There are {} columns have more than {}% missing value\".format(len(missing_columns), thresh))\n",
    "    \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has 655 columns.\n",
      "There are 621 columns that have missing value.\n",
      "Dataframe has 654 columns.\n",
      "There are 615 columns that have missing value.\n",
      "There are 5 columns have more than 90% missing value\n"
     ]
    }
   ],
   "source": [
    "train, test = drop_missing_values(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (307507, 650) and test: (48744, 649)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train: {} and test: {}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, test_features, n_folds = 10):\n",
    "    \"\"\" Train and test a light gradient boosting model using cross validation\n",
    "    Parameters\n",
    "    ---------\n",
    "        features (pd.DataFrame): dataframe of training dataset, must have TARGET column\n",
    "        test_features (pd.DataFrame): dataframe of testing dataset\n",
    "        encoding (str, default = ohe): method for encoding categorical variable, ohe for one-hot encoder and le for integer label encoding\n",
    "        n_folds (int, default = 5): number of fold to use for cross validation\n",
    "    Return\n",
    "    ---------\n",
    "        submission (pd.DataFrame): have two column 'SK_ID_CURR' and 'TARGET' proba predicted bt the model\n",
    "        feature_importances (pd.DataFrame): dataframe with feature importance from model\n",
    "        valid_metrics (pd.DataFrame): dataframe with training and validation metrics (ROC AUC) for each fold and overall\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "\n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "\n",
    "    # Remove the ids and target\n",
    "\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "\n",
    "\n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits= n_folds, shuffle= True, random_state= 50)\n",
    "\n",
    "    # Empty array for features importance\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "\n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "\n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "\n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features.iloc[train_indices], labels.iloc[train_indices]\n",
    "\n",
    "        # validation data for the fold\n",
    "        valid_features, valid_labels = features.iloc[valid_indices], labels.iloc[valid_indices]\n",
    "\n",
    "        # Create model\n",
    "        model = lgb.LGBMClassifier(n_estimators= 10000, objective='binary', class_weight= 'balanced', learning_rate= 0.02, max_depth=8, reg_alpha= 0.04, reg_lambda= 0.073, subsample= 0.8715623, n_jobs= -1, random_state= 50, num_leaves= 34, colsample_bytree= 0.9497036, min_split_gain= 0.0222415, min_child_weight= 39.3259775, silent= -1, verbose = -1)\n",
    "\n",
    "        # Train the model\n",
    "        model = model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                    eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                    eval_names = ['valid', 'train'],\n",
    "                    categorical_feature = 'auto',\n",
    "                    early_stopping_rounds = 100,\n",
    "                    verbose = 200   )\n",
    "\n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "\n",
    "        # Record the feature importance\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "\n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:,1] / k_fold.n_splits\n",
    "\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:,1]\n",
    "\n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "\n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        # Make confusion matrix\n",
    "        confusion_matrix += (ConfusionMatrixDisplay.from_estimator(model,\n",
    "                        valid_features,\n",
    "                        valid_labels,\n",
    "                        display_labels = ['0','1'],\n",
    "                        normalize = 'true').confusion_matrix) / k_fold.n_splits\n",
    "        \n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "\n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "\n",
    "    # Make the feature importance dataFrame\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "\n",
    "    # Make confusion matrix dataframe\n",
    "    confusion_matrix = pd.DataFrame(confusion_matrix, index=['0', '1'], columns= ['0', '1'])\n",
    "\n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "\n",
    "    # Add the overall scores to the metric\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "\n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    # \n",
    "\n",
    "    return submission, feature_importances, metrics, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.43 GiB for an array with shape (625, 307507) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13020\\1794805305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13020\\1736685847.py\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(features, test_features, n_folds)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Remove the ids and target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'SK_ID_CURR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'SK_ID_CURR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4952\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4953\u001b[0m         \"\"\"\n\u001b[1;32m-> 4954\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4955\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4267\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4349\u001b[0m         \u001b[0mbm_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maxis_num\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4350\u001b[1;33m         new_mgr = self._mgr.reindex_indexer(\n\u001b[0m\u001b[0;32m   4351\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4352\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    842\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m                         \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         new_values = algos.take_nd(\n\u001b[0m\u001b[0;32m   1140\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\quyk5\\anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.43 GiB for an array with shape (625, 307507) and data type float64"
     ]
    }
   ],
   "source": [
    "submission, fi, metrics, cm = model(train, test, n_folds= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('final.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = fi.sort_values('importance', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fi[fi.importance == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbbf29e62cd5103f0785fc846693ce8698ed050f8e69bcd7649d2aec785d2f26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
